{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24c9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804f854",
   "metadata": {},
   "source": [
    "### Generating the Dataset\n",
    "\n",
    "\n",
    "(**$$y = 5 + 1.2x - 3.4\\frac{x^2}{2!} + 5.6 \\frac{x^3}{3!} + \\epsilon \\text{ where }\n",
    "\\epsilon \\sim \\mathcal{N}(0, 0.1^2).$$**)\n",
    "\n",
    "The noise term $\\epsilon$ obeys a normal distribution\n",
    "with a mean of 0 and a standard deviation of 0.1.\n",
    "For optimization, we typically want to avoid\n",
    "very large values of gradients or losses.\n",
    "This is why the *features*\n",
    "are rescaled from $x^i$ to $\\frac{x^i}{i!}$.\n",
    "It allows us to avoid very large values for large exponents $i$.\n",
    "We will synthesize 100 samples each for the training set and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf572814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]]\n"
     ]
    }
   ],
   "source": [
    "max_degree = 20 \n",
    "n_train, n_test = 100, 100\n",
    "true_w = np.zeros(max_degree)  # create a (1, 20) matrix\n",
    "true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])  # give 4 values in the first four cols\n",
    "\n",
    "features = np.random.normal(size=(n_train + n_test, 1))  # create a (200, 1) matrix\n",
    "np.random.shuffle(features)\n",
    "poly_features = np.power(features, np.arange(max_degree).reshape(1, -1)) \n",
    "                # np.power(a,b) = a^b (element by element through broadcasting)\n",
    "\n",
    "for i in range(max_degree):\n",
    "    poly_features[:, i] /= math.gamma(i+1)\n",
    "    \n",
    "labels = np.dot(poly_features, true_w)\n",
    "labels += np.random.normal(scale=0.1, size=labels.shape)  # scale = variance; loc = average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2da731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [5.]\n",
      " [8.]\n",
      " [9.]]\n",
      "[[  1.   1.]\n",
      " [  4.   8.]\n",
      " [  9.  27.]\n",
      " [ 25. 125.]\n",
      " [ 64. 512.]\n",
      " [ 81. 729.]]\n"
     ]
    }
   ],
   "source": [
    "# np.power(a,b) = a^b (element by element through broadcasting)\n",
    "# For testing\n",
    "A = np.array([[1.0], [2.0], [3.0], [5.0], [8.0], [9.0]])\n",
    "B = np.array([2.0, 3.0])\n",
    "C = np.power(A, B)\n",
    "print(A)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f32f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
