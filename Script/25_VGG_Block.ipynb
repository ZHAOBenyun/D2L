{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cdf747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df819bc",
   "metadata": {},
   "source": [
    "### Define the VGG Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6a0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []  # create an empty list for contain different layers\n",
    "    for _ in range(num_convs):  # _ means a parameter which will not be used in For Loop\n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels   # after appending one layers, replace the input channel with output channels\n",
    "                                     # since the second layer's input is the first layer's output\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))  # after appending all convolutional layers, add one maxpooling layer\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0af5e8",
   "metadata": {},
   "source": [
    "### Build the VGG Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ceecce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of blocks are 5 which cannot be changed\n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "\n",
    "def vgg(conv_arch):\n",
    "    conv_blks = []  # create an empty list for contain different vgg blocks\n",
    "    in_channels = 1   # the dimension of First input channel is 1\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))   # put different vgg blocks into the convolutional block\n",
    "        in_channels = out_channels   # after appending one layers, replace the input channel with output channels\n",
    "                                     # since the second layer's input is the first layer's output\n",
    "    \n",
    "    return nn.Sequential(*conv_blks, nn.Flatten(), \n",
    "                         nn.Linear(out_channels*7*7, 4096), nn.ReLU(),\n",
    "                         nn.Dropout(p=0.5), \n",
    "                         nn.Linear(4096, 4096), nn.ReLU(), \n",
    "                         nn.Dropout(0.5),\n",
    "                         nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4c7672",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf54a7",
   "metadata": {},
   "source": [
    "### Show the VGG Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0969e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorch1.9\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 224, 224))\n",
    "for block in net:\n",
    "    X = block(X)\n",
    "    print(block.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ab9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "# get all pairs in conv_arch and reduce them 4 times\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "small_net = vgg(small_conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ddb549",
   "metadata": {},
   "source": [
    "### Train the VGG Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fdc9e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pytorch1.9\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs, batch_size = 0.05, 10, 8\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch6(small_net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd49b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
